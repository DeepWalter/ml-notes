\section{Multilayer Feedforward Networks are Universal Approximators}
This paper\cite{hornik_1989} proves that standard multilayer feedforward networks with as few as one hidden 
layer using arbitrary squashing functions are capable of approximating any Borel measureble function, provided
sufficiently many hidden units are available.

\subsection{Terminology and Notation}
Let $\boldsymbol{A}^r = \left\{A: \mathbb{R}^r \longrightarrow \mathbb{R} | A(\V{x}) = \langle \V{w}, \V{x}
\rangle + b\right\}$ be the collection of all affine functions, $\boldsymbol{M}^r$ the collection of all 
Borel measureble functions, $\boldsymbol{C}^r$ the collection of all continuous functions and 
$\boldsymbol{B}^r$ the collection of all Borel sets, on $\mathbb{R}^r$.

\begin{df}[Squashing function]
    $\phi: \mathbb{R}\longrightarrow [0, 1]$ is a squashing function if and only if it is 
    non-decreasing, satifies $\displaystyle\lim_{\lambda \to \infty}\phi(\lambda) = 1$ and 
    $\displaystyle\lim_{\lambda \to -\infty}\phi(\lambda) = 0$.
\end{df}

\begin{df}
    Let $G: \mathbb{R} \longrightarrow \mathbb{R}$ be a Borel measureble function. Then 
    $\boldsymbol{\Sigma}^r(G)$ is defined as:
    $$\boldsymbol{\Sigma}^r(G) = \bigg\{f: \mathbb{R}^r \longrightarrow \mathbb{R} \Big| f(\V{x}) = 
    \sum_{j = 1}^q \beta_j G(A_j(\V{x})),\; q\in\mathbb{N}, \beta_j\in\mathbb{R}, A_j\in\boldsymbol{A}^r
    \bigg\}$$
    Obviously, functions in $\boldsymbol{\Sigma}^r(G)$ are the outputs of neuron networks which have a single
    hidden layer with activation $G$ (no activation in the output layer).
\end{df}

\begin{df}
    Let $G: \mathbb{R} \longrightarrow \mathbb{R}$ be a Borel measureble function. Then 
    $\boldsymbol{\Sigma\Pi}^r(G)$ is defined as:
    $$\boldsymbol{\Sigma\Pi}^r(G) = \bigg\{f: \mathbb{R}^r \longrightarrow \mathbb{R} \Big| f(\V{x}) = 
    \sum_{j = 1}^q \beta_j\prod_i^{l_j} G(A_i(\V{x}))\bigg\}$$
    Obviously, $\boldsymbol{\Sigma\Pi}^r(G)$ is the algebra generated by $\boldsymbol{\Sigma}^r(G)$.
\end{df}

\begin{df}
    Let $(X, \rho)$ be a metric space, $S \subseteq T \subseteq X$. Then $S$ is said to be $\rho$-dense in $T$ 
    if $\forany \varepsilon > 0, \forany t \in T, \thereis s \in S, \st \rho(s, t) < \varepsilon$.
\end{df}

\begin{df}
    $S \subseteq \boldsymbol{C}^r$ is \textbf{uniformly dense on compacta} in $\boldsymbol{C}^r$ if $\forany K
    \subseteq \mathbb{R}^r$ which is compact, $S$ is $\rho_K$-dense in $\boldsymbol{C}^r$. A sequence 
    $\{f_n\}$ converges to $f$ uniformly on compacta if $\forany K \subseteq \mathbb{R}^r$ compact, 
    $\displaystyle\lim_{n\to\infty}\rho_K(f_n, f) = 0$. Here the metric 
    $\rho_K$ is defined as:
    $$\rho_K(f, g) = \sup_{\V{x}\in K}|f(\V{x}) - g(\V{x})|\quad\forany f, g\in \boldsymbol{C}^r$$
\end{df}